---
title: "Bradley-Terry models in lmerMultiMember"
output: rmarkdown::html_vignette
author: "Jeroen van Paridon"
date: "2022-10-20"
vignette: >
  %\VignetteIndexEntry{Bradley-Terry models in lmerMultiMember}
  \usepackage[utf8]{inputenc}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: inline
---

## Off-label usage of lmerMultiMember

The ability to pass arbitrary random effects matrices to `lme4` makes `lmerMultiMember` useful for more than just vanilla multiple membership models. Any model that can be specified as a combination of "conventional" fixed effects and an arbitrary random effects matrix can be specified using `lmerMultiMember`. (Although for certain model specifications the underlying `lme4` model fitting may not converge.)

One class of models that can be fit using lmerMultiMember is Bradley-Terry models, used to predict the probability of a given individual winning in a paired comparison with another individual, even when information is incomplete (i.e. not every individual has directly encountered every other individual). One example application is to predict rankings of chess players, even if not each player in the list has played every other player.

The Bradley-Terry model can be written as a Generalized Linear Mixed-effects Model (GLMM) as follows:
$$\operatorname{logit}(P(i > j)) = \log\left(\frac{P(i > j)}{1 - P(i > j)}\right) = \log\left(\frac{P(i > j)}{P(j > i)}\right) = \beta_i - \beta_j$$
This formulation of the Bradley-Terry model is a logistic regression with a random effects matrix that has positive indicators for one individual in the comparison and negative indicators for the other. In this formulation we model the probability the the individual with the positive indicator "wins" the comparison. There is often a natural way to assign individuals to sides of the comparison, for instance by always giving the home team the positive indicator (in this case, if we model an intercept, that intercept represents the home field advantage) or, in chess, to always assign the player with the white pieces the positive indicator.

`lmerMultiMember::bradleyterry_from_vectors()` is a helper function that creates the indicator matrix from a vector of home teams (i.e. individuals that will be assigned positive indicators) and a vector of visiting teams (i.e. individuals that will be assigned negative indicators). If this function is used to generate the indicator matrix, we will be modeling the probability of the home team winning.

### Predicting NFL team rankings for the 2021 season

To demonstrate how to specify and fit a Bradley-Terry model in `lmerMultiMember`, in this vignette we will rank National Football League teams by their performance in the 2021 season, even for teams who did not play a single game against each other during that season.

NFL scores for the 2021 season are included with `lmerMultiMember` as a dataset, so all we need to do to load the data is load the package itself. Then, we can take a quick look at the data.

```{r load_package}
library(lmerMultiMember)
knitr::kable(nfl_scores_2021)
```

### Toy dataset

First, we generate a toy dataset with wins

```{r toy_data}

df <- data.frame(
  #wins = c(rep(1, 14), 0),
  #wins = rep(1, 15),
  wins =    c( 1,   1,   1,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   1,   1,   0,   0,   0,   1,   0,   0,   0),
  losers = c("a", "a", "a", "a", "a", "a", "a", "a", "a", "a", "b", "b", "b", "b", "b", "b", "b", "b", "c", "c", "c", "c"),
  winners =  c("b", "b", "d", "b", "b", "b", "d", "d", "d", "d", "c", "c", "c", "c", "c", "c", "c", "c", "d", "d", "d", "d")
)

df2 <- data.frame(
  #wins = c(rep(1, 14), 0),
  #wins = rep(1, 15),
  wins =    c( 1,   1,   1,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   1,   1,   0,   0,   0,   1,   0,   0,   0),
  winners = c("a", "a", "a", "b", "b", "b", "d", "d", "d", "d", "b", "b", "b", "b", "b", "c", "c", "c", "c", "d", "d", "d"),
  losers =  c("b", "b", "d", "a", "a", "a", "a", "a", "a", "a", "c", "c", "c", "c", "c", "b", "b", "b", "d", "c", "c", "c")
)
W <- bradleyterry_from_vectors(df$winners, df$losers)
m <- glmer(wins ~ (1 | indicators), family = binomial, memberships = list(indicators = W), data = df)
summary(m)

```


```{r baseballmodel}

load("~/Downloads/toy_data.rda")
toy_data
toy_data$wins <- dplyr::recode(toy_data$outcome, W1 = 1, D = .5, W2 = 0) * 2
toy_data$losses <- 2 - toy_data$wins
toy_data
W <- bradleyterry_from_vectors(toy_data$player1, toy_data$player2)
m <- glmer(cbind(wins, losses)  ~ (1 | indicators), family = binomial, memberships = list(indicators = W), data = toy_data)
summary(m)

```


```{r, fig.width=4, fig.height=3}
df <- data.frame(
  outcome = rbinom(10000, 1, .8),
  home_team = rep("A", 10000),
  visiting_team = rep("B", 10000)
)

W <- bradleyterry_from_vectors(df$home_team, df$visiting_team)
m <- glmer(outcome ~ 0 + (1 | indicators), family = binomial, memberships = list(indicators = W), data = df)
summary(m)

dd <- broom.mixed::tidy(m, effects = "ran_vals")
dd <- transform(dd, level = reorder(level, estimate))

dd$estimate
boot::inv.logit(dd$estimate)

pnorm(dd$estimate, sd = .85)
pbeta(boot::inv.logit(dd$estimate), 3.3, 3.3)

# .50 with p = .5
# .55 with p = .6
# .60 with p = .7
# .66 with p = .8
# .75 with p = .9
# .81 with p = .95
# .91 with p = .99

estBetaParams <- function(mu, var) {
  alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
  beta <- alpha * (1 / mu - 1)
  return(params = list(alpha = alpha, beta = beta))
}

estBetaParams(.5, .033)


ggplot(dd, aes(x = level, y = estimate)) +
  geom_pointrange(aes(
    ymin = estimate - 2 * std.error,
    ymax = estimate + 2 * std.error
  )) +
  coord_flip()
```
